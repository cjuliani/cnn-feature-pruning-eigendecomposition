# Brute force filter pruning of convolutional neural network models
![Tensorflow](https://img.shields.io/badge/Implemented%20in-Tensorflow-green.svg) <br>

The demo was developed for pruning filters from a U-Net (see [model](https://github.com/cjuliani/tf-unet-multiclass)). Input data are *32x32* pixels samples of elevation data and RGB terrain attributes representing single mounds - the output is a segmentated blob corresponding to the mound. The project includes a pre-train U-Net model (with 1 output), data processing and model inference modules, and a pruning system from which feature maps of a given convolutional layer can be visalized and saved. The pruning procedure first calculate the importance of feature layer-per-layer with the singular value decomposition method, and retains 99% of convolutional information generated by the model for each layer. Then, filters associated to the remaining 1% information are pruned by assigning 0 to the filter masks, and the model performance is tested with pruned filters. If the performance does not change drastically (given an accuracy change, see figure below) then the pruning procedure ends. Otherwise, we reconsider pruned filters one by one and test the model performance gradually to achieve a small an accuracy change.

| ![alt text](https://raw.githubusercontent.com/cjuliani/tf-cnn-pruning/master/scheme.png) |
|:--:|
| *Overview of the iterative pruning procedure: (1) get activation signals of a convolutional layer from a trained CNN, (2) apply eigendecomposition method to retain e.g. 99% of most important features within the layer, (3) apply pruning given activations signals retained (by setting filters to 0) and get indices of filters pruned, (4) test the CNN with pruned filters to check the accuracy change (ε) i.e. if pruning affected to some degree the model performance, and (5) if ε is below an arbitrary threshold γ, re-iterate the procedure from (3) to (5) after converting 1 pruned filter to a non-pruned filter so that we retrieve gradually information from the 1% features ruled out by eigendecomposition as long as ε < γ.*
